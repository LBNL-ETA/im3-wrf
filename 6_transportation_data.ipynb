{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "def list_geojson_properties(geojson):\n",
    "    print('GeoJson properties:\\n' + \"; \".join(geojson['properties']))\n",
    "    print('GeoJson geometry coordinates: ' + str(geojson['geometry']['coordinates'][0][0]))\n",
    "\n",
    "def get_polygon_from_geojson_geometry(geometry):\n",
    "    polygon_list = list()\n",
    "    if geometry['type'] == 'MultiPolygon':\n",
    "        for polygon in geometry['coordinates']:\n",
    "            polygon_list.append(Polygon(polygon[0]))\n",
    "    elif geometry['type'] == 'Polygon':\n",
    "        polygon_list.append(Polygon(geometry['coordinates'][0]))\n",
    "    return polygon_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read county boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDARIES_NAME = 'domain/la-county-boundary.geojson'\n",
    "districts_data = dict()\n",
    "with open(BOUNDARIES_NAME, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    district_list = data['features']\n",
    "\n",
    "for district in district_list:\n",
    "    district_name = str(district['properties']['OBJECTID'])\n",
    "    district_name = district_name.replace(' ', '_')\n",
    "    districts_data[district_name] = dict()\n",
    "    districts_data[district_name]['coordinates'] = get_polygon_from_geojson_geometry(district['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shapefile\n",
    "# read_transportation = False\n",
    "# if read_transportation:\n",
    "#     CITY_FOLDER_NAME = 'la-five'\n",
    "#     INPUT_FILE_NAME = 'SOCAL10_Emissions_Inventory_500m_Annual_CO2_WGS'\n",
    "#     OUTPUT_FILE_NAME = 'LA_CO2_WGS'\n",
    "\n",
    "\n",
    "#     reader = shapefile.Reader(os.path.join(CITY_FOLDER_NAME, INPUT_FILE_NAME + '.shp'))\n",
    "#     fields = reader.fields[1:]\n",
    "#     field_names = [field[0] for field in fields]\n",
    "#     buffer = []\n",
    "#     count = 0\n",
    "#     geojson = open(os.path.join(CITY_FOLDER_NAME, OUTPUT_FILE_NAME + '.geojson'), 'w')\n",
    "#     for sr in reader.shapeRecords():\n",
    "#         count += 1\n",
    "#         atr = dict(zip(field_names, sr.record))\n",
    "#         geom = sr.shape.__geo_interface__\n",
    "#         buffer.append(dict(type=\"Feature\", geometry=geom, properties=atr))\n",
    "#         if count % 10000 == 0:\n",
    "#             sys.stdout.write(\"\\rTotal building processed: %d\" % count)\n",
    "#             sys.stdout.flush()\n",
    "\n",
    "#     sys.stdout.write(\"\\rTotal building processed: %d\" % count)\n",
    "#     sys.stdout.flush()\n",
    "#     geojson.write(json.dumps({\"type\": \"FeatureCollection\", \"features\": buffer}, indent=2))\n",
    "#     geojson.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping transportation grids to WRF grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transportation-data/transportation-sep/LA_CO2_WGS.geojson', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    data_json = data['features']\n",
    "    trans_grid_data = dict()\n",
    "    for grid_data in data_json:\n",
    "        grid_id = str(grid_data['properties']['Id'])\n",
    "        trans_grid_data[grid_id] = get_polygon_from_geojson_geometry(grid_data['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_grid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grid processed: 171008"
     ]
    }
   ],
   "source": [
    "trans_grid_data_domain = dict()\n",
    "count = 0\n",
    "for grid_id in trans_grid_data:\n",
    "    count += 1\n",
    "    poly = trans_grid_data[grid_id]\n",
    "    for district in districts_data: \n",
    "        district_poly = districts_data[district]['coordinates'][0]\n",
    "        centroid = poly[0].centroid\n",
    "        if district_poly.contains(centroid) > 0:\n",
    "            trans_grid_data_domain[grid_id] = centroid\n",
    "            break\n",
    "    if count % 10000 == 0:\n",
    "        sys.stdout.write(\"\\rTotal grid processed: %d\" % count)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "sys.stdout.write(\"\\rTotal grid processed: %d\" % count)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41048"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_grid_data_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT (-118.4347229125807 32.81456010610546)\n"
     ]
    }
   ],
   "source": [
    "print(trans_grid_data_domain['92029'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grid processed: 130170, found: 29953"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "found = 0\n",
    "with open('bldg-wrf-mapping/wrf-grids-origin.geojson', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    wrf_grids = data['features']\n",
    "    for wrf_grid in wrf_grids:\n",
    "        count += 1\n",
    "        wrf_poly = get_polygon_from_geojson_geometry(wrf_grid['geometry'])[0]\n",
    "        for grid_id in trans_grid_data_domain:\n",
    "            trans_centroid = trans_grid_data_domain[grid_id]\n",
    "            if wrf_poly.contains(trans_centroid):\n",
    "                wrf_grid['properties']['trans_grid_id'] = grid_id\n",
    "                found += 1\n",
    "                break\n",
    "        if count % 10 == 0:\n",
    "            sys.stdout.write(\"\\rTotal grid processed: %d, found: %d\" % (count, found))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    if count % 10 == 0:\n",
    "        sys.stdout.write(\"\\rTotal grid processed: %d, found: %d\" % (count, found))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('bldg-wrf-mapping/wrf-trans-map.csv', 'w')\n",
    "ind = -1\n",
    "row = 384\n",
    "col = 339\n",
    "for i in range(row):\n",
    "    for j in range(col):\n",
    "        ind += 1\n",
    "        if 'trans_grid_id' in wrf_grids[ind]['properties']:\n",
    "            trans_grid_id = wrf_grids[ind]['properties']['trans_grid_id']\n",
    "        else:\n",
    "            trans_grid_id = -1\n",
    "        out.write(str(trans_grid_id) + \",\")\n",
    "    out.write('\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read tranportation emission data and write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data = dict()\n",
    "df = pd.read_csv(os.path.join('transportation-sep', 'Sunday.csv'), \n",
    "                 sep=',', parse_dates=True, infer_datetime_format=True, encoding='UTF-8')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    trans_data[str(int(row[\"id\"]))] = list(row)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_prefixs = [\"Variable_TRANSHEAT_20090920\", \"Variable_TRANSHEAT_20090927\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.interpolate(method='ffill', limit=1)\n",
    "df_trans = df_trans.fillna(-1)\n",
    "df_trans.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.to_csv('bldg-wrf-mapping/wrf-trans-map-grid-fillna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_csv('bldg-wrf-mapping/wrf-trans-map-grid-fillna.csv', sep=',', parse_dates=True, infer_datetime_format=True, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name_prefix in file_name_prefixs:\n",
    "    for hour in range(25):\n",
    "        file_name = 'transportation-data/wrf-trans-out/' + file_name_prefix + str(hour).zfill(2) + '.txt'\n",
    "        with open(file_name, 'w') as out:\n",
    "            for index, row in df_trans.iterrows():\n",
    "                line = \"\"\n",
    "                cur_row = list(row)\n",
    "                for grid in cur_row:\n",
    "                    try:\n",
    "                        line += str(trans_data[str(int(grid))][hour]) + \",\"\n",
    "                    except:\n",
    "                        line += \"0.0,\"\n",
    "                out.write(line[:-1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
